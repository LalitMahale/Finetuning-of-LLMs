{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7087930,"sourceType":"datasetVersion","datasetId":4083967}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-23T09:58:04.867307Z","iopub.execute_input":"2024-08-23T09:58:04.867715Z","iopub.status.idle":"2024-08-23T09:58:05.243749Z","shell.execute_reply.started":"2024-08-23T09:58:04.867667Z","shell.execute_reply":"2024-08-23T09:58:05.242605Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/mathinstruct-dataset-hybrid-math-instruction-tun/train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install -U datasets # To convert dataset into huggingface dataset format\n%pip install accelerate # \n%pip install peft # For finetuning and LoRa ","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:58:05.245831Z","iopub.execute_input":"2024-08-23T09:58:05.246362Z","iopub.status.idle":"2024-08-23T09:58:44.681237Z","shell.execute_reply.started":"2024-08-23T09:58:05.246303Z","shell.execute_reply":"2024-08-23T09:58:44.680050Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.33.0)\nRequirement already satisfied: numpy<2.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.24.6)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\nCollecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.33.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.4)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.12.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load model and Tokenizer","metadata":{}},{"cell_type":"code","source":"import torch\nimport transformers\nfrom transformers import (AutoModelForCausalLM,AutoTokenizer, BitsAndBytesConfig,\n                          HfArgumentParser,TrainingArguments,Pipeline,logging)\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:58:44.682627Z","iopub.execute_input":"2024-08-23T09:58:44.682949Z","iopub.status.idle":"2024-08-23T09:59:04.182281Z","shell.execute_reply.started":"2024-08-23T09:58:44.682915Z","shell.execute_reply":"2024-08-23T09:59:04.181501Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model_id = \"databricks/dolly-v2-3b\"","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:04.183615Z","iopub.execute_input":"2024-08-23T09:59:04.184748Z","iopub.status.idle":"2024-08-23T09:59:04.190835Z","shell.execute_reply.started":"2024-08-23T09:59:04.184701Z","shell.execute_reply":"2024-08-23T09:59:04.189962Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Tokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntokenizer.pad_token = tokenizer.eos_token\n\n\"\"\"\nBy setting tokenizer.pad_toke = tokenizer.eos_token,\nThe code is instructing the tokenizer to ues the end-of-sequence token as the padding token.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:04.193817Z","iopub.execute_input":"2024-08-23T09:59:04.194169Z","iopub.status.idle":"2024-08-23T09:59:05.702141Z","shell.execute_reply.started":"2024-08-23T09:59:04.194137Z","shell.execute_reply":"2024-08-23T09:59:05.701189Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d8a238b7fd04e34b86ac89f64c77f4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fffca3a23af645a6a960574b551c0ba9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/228 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaa94e5d21844f138c51454b7d085fce"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'\\nBy setting tokenizer.pad_toke = tokenizer.eos_token,\\nThe code is instructing the tokenizer to ues the end-of-sequence token as the padding token.\\n'"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(model_id, \n#                                              use_cache = False,\n                                            device_map = \"auto\", # balance\n                                            load_in_8bit = False, # NO Quantized model we need here \n                                            torch_dtype = torch.float16)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:05.703726Z","iopub.execute_input":"2024-08-23T09:59:05.704040Z","iopub.status.idle":"2024-08-23T09:59:31.127351Z","shell.execute_reply.started":"2024-08-23T09:59:05.704007Z","shell.execute_reply":"2024-08-23T09:59:31.126506Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93c26a974b9e4e23b80b3651437d5058"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/5.68G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57dcc0a28076493cb19c2969a1907387"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Import Required Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport random\nfrom datasets import Dataset,disable_caching\nfrom typing import Dict,List\nfrom copy import deepcopy\nfrom functools import partial\nfrom transformers import DataCollatorForSeq2Seq\n\ndisable_caching()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:31.128700Z","iopub.execute_input":"2024-08-23T09:59:31.129541Z","iopub.status.idle":"2024-08-23T09:59:31.651827Z","shell.execute_reply.started":"2024-08-23T09:59:31.129492Z","shell.execute_reply":"2024-08-23T09:59:31.651078Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Preparation","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/mathinstruct-dataset-hybrid-math-instruction-tun/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:31.652920Z","iopub.execute_input":"2024-08-23T09:59:31.653542Z","iopub.status.idle":"2024-08-23T09:59:44.169850Z","shell.execute_reply.started":"2024-08-23T09:59:31.653495Z","shell.execute_reply":"2024-08-23T09:59:44.168793Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                            source  \\\n0           data/CoT/aqua_rat.json   \n1           data/CoT/aqua_rat.json   \n2  data/PoT/aqua_rat_filtered.json   \n3            data/CoT/gsm_rft.json   \n4  data/PoT/aqua_rat_filtered.json   \n\n                                         instruction  \\\n0  The distance between two stars is 6.52 × 10^5 ...   \n1  How many ways can the letters in the word COMM...   \n2  A team of six entered for a shooting competiti...   \n3  A psychiatrist has 4 patients that need 25 ses...   \n4  The radius of a wheel is 22.4 cm. What is the ...   \n\n                                              output  \n0  Let's think about the multi-choice question.\\n...  \n1  Let's solve the multi-choice question step by ...  \n2  answers = ['A', 'B', 'C', 'D', 'E']\\n# If the ...  \n3  The second patient needs 6+5 = 11 sessions\\n25...  \n4  radius = 22.4\\nresolutions = 500\\n# calculate ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>instruction</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>data/CoT/aqua_rat.json</td>\n      <td>The distance between two stars is 6.52 × 10^5 ...</td>\n      <td>Let's think about the multi-choice question.\\n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>data/CoT/aqua_rat.json</td>\n      <td>How many ways can the letters in the word COMM...</td>\n      <td>Let's solve the multi-choice question step by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>data/PoT/aqua_rat_filtered.json</td>\n      <td>A team of six entered for a shooting competiti...</td>\n      <td>answers = ['A', 'B', 'C', 'D', 'E']\\n# If the ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>data/CoT/gsm_rft.json</td>\n      <td>A psychiatrist has 4 patients that need 25 ses...</td>\n      <td>The second patient needs 6+5 = 11 sessions\\n25...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>data/PoT/aqua_rat_filtered.json</td>\n      <td>The radius of a wheel is 22.4 cm. What is the ...</td>\n      <td>radius = 22.4\\nresolutions = 500\\n# calculate ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"prompt = \"\"\"Below is an instruction and output. Understand  the Instruction and accordingly give the ouput. \\n\\nInstruction : {instruction}\\n\\n\"\"\"\n\nanswer = \"\"\"Answer : {output}\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:44.170995Z","iopub.execute_input":"2024-08-23T09:59:44.171308Z","iopub.status.idle":"2024-08-23T09:59:44.175594Z","shell.execute_reply.started":"2024-08-23T09:59:44.171268Z","shell.execute_reply":"2024-08-23T09:59:44.174625Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def data_preprocess(df):\n    def error_raise(col_name):\n        raise ValueError(f\"Expected an {col_name} in dataframe\")\n    instruction = df['instruction']\n    output = df[\"output\"]\n    if not instruction:\n        error_raise(instruction)\n    if not output:\n        error_raise(output)\n    prompt1 = prompt.format(instruction = instruction)\n    answer1 = answer.format(output = output)\n    df[\"text\"] = prompt1 + answer1\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:44.176979Z","iopub.execute_input":"2024-08-23T09:59:44.177372Z","iopub.status.idle":"2024-08-23T09:59:47.178996Z","shell.execute_reply.started":"2024-08-23T09:59:44.177326Z","shell.execute_reply":"2024-08-23T09:59:47.178000Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df.columns\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:47.180158Z","iopub.execute_input":"2024-08-23T09:59:47.180540Z","iopub.status.idle":"2024-08-23T09:59:47.191545Z","shell.execute_reply.started":"2024-08-23T09:59:47.180502Z","shell.execute_reply":"2024-08-23T09:59:47.190564Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Index(['source', 'instruction', 'output'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"## Taking small dataset from whole dataset which is 1% of whole data \nindex = random.sample(range(df.shape[0]),round(df.shape[0]*0.01))\nsmall_dataset = df.iloc[index]\nsmall_dataset.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:47.192797Z","iopub.execute_input":"2024-08-23T09:59:47.193304Z","iopub.status.idle":"2024-08-23T09:59:47.208070Z","shell.execute_reply.started":"2024-08-23T09:59:47.193263Z","shell.execute_reply":"2024-08-23T09:59:47.207301Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"small_dataset = small_dataset.apply(data_preprocess,axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:47.209064Z","iopub.execute_input":"2024-08-23T09:59:47.209358Z","iopub.status.idle":"2024-08-23T09:59:48.677412Z","shell.execute_reply.started":"2024-08-23T09:59:47.209327Z","shell.execute_reply":"2024-08-23T09:59:48.676414Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(small_dataset.text[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:48.683147Z","iopub.execute_input":"2024-08-23T09:59:48.683497Z","iopub.status.idle":"2024-08-23T09:59:48.688622Z","shell.execute_reply.started":"2024-08-23T09:59:48.683462Z","shell.execute_reply":"2024-08-23T09:59:48.687660Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Below is an instruction and output. Understand  the Instruction and accordingly give the ouput. \n\nInstruction :  \"statement 1\": 180 , calculate the dividend from Carol ' s stock ., \"statement 2\" :less than 880 , calculate the dividend from Carol ' s stock ., \"options: \" Entailment or contradiction or neutral? Let's program in Python in the response.\n\nAnswer : carol_stock_s1 = 180\ncarol_stock_s2 = 880\n \nif carol_stock_s1 is None or carol_stock_s2 is None:\n print('neutral')\n\nelif carol_stock_s1 < carol_stock_s2:\n print('Entailment')\n\nelif carol_stock_s1 != carol_stock_s2:\n print('contradiction')\n","output_type":"stream"}]},{"cell_type":"code","source":"hf_dataset = Dataset.from_pandas(small_dataset)\nhf_dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:48.689868Z","iopub.execute_input":"2024-08-23T09:59:48.690177Z","iopub.status.idle":"2024-08-23T09:59:48.744909Z","shell.execute_reply.started":"2024-08-23T09:59:48.690146Z","shell.execute_reply":"2024-08-23T09:59:48.744014Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['index', 'source', 'instruction', 'output', 'text'],\n    num_rows: 2623\n})"},"metadata":{}}]},{"cell_type":"code","source":"MAX_LENGTH = 512","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:48.746047Z","iopub.execute_input":"2024-08-23T09:59:48.746390Z","iopub.status.idle":"2024-08-23T09:59:48.750586Z","shell.execute_reply.started":"2024-08-23T09:59:48.746352Z","shell.execute_reply":"2024-08-23T09:59:48.749477Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def _preprocessing_batch(batch:Dict[str,List]):\n    model_input  = tokenizer(batch[\"text\"],max_length=MAX_LENGTH, \n                            truncation=True, padding=\"max_length\"\n                            )\n    model_input[\"labels\"] = deepcopy(model_input[\"input_ids\"])\n    return model_input","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:48.751637Z","iopub.execute_input":"2024-08-23T09:59:48.751911Z","iopub.status.idle":"2024-08-23T09:59:48.760837Z","shell.execute_reply.started":"2024-08-23T09:59:48.751872Z","shell.execute_reply":"2024-08-23T09:59:48.759998Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"preprocessing_fuc = partial(_preprocessing_batch)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:48.761800Z","iopub.execute_input":"2024-08-23T09:59:48.762070Z","iopub.status.idle":"2024-08-23T09:59:48.773631Z","shell.execute_reply.started":"2024-08-23T09:59:48.762040Z","shell.execute_reply":"2024-08-23T09:59:48.772729Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:48.774874Z","iopub.execute_input":"2024-08-23T09:59:48.775642Z","iopub.status.idle":"2024-08-23T09:59:48.785822Z","shell.execute_reply.started":"2024-08-23T09:59:48.775599Z","shell.execute_reply":"2024-08-23T09:59:48.784984Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Index(['source', 'instruction', 'output'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"encoded_small_dataset = hf_dataset.map(\npreprocessing_fuc, \nbatched = True,\nremove_columns = [\"instruction\",\"source\",\"output\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:48.786893Z","iopub.execute_input":"2024-08-23T09:59:48.787177Z","iopub.status.idle":"2024-08-23T09:59:51.657201Z","shell.execute_reply.started":"2024-08-23T09:59:48.787140Z","shell.execute_reply":"2024-08-23T09:59:51.656427Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2623 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"896e2452f5d7417c865f77f8582885f3"}},"metadata":{}}]},{"cell_type":"code","source":"processed_dataset = encoded_small_dataset.filter(lambda rec : len(rec[\"input_ids\"])<= MAX_LENGTH)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:51.658337Z","iopub.execute_input":"2024-08-23T09:59:51.658651Z","iopub.status.idle":"2024-08-23T09:59:54.114366Z","shell.execute_reply.started":"2024-08-23T09:59:51.658619Z","shell.execute_reply":"2024-08-23T09:59:54.113471Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2623 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519b6d286b5f4091898d240911c2b0a7"}},"metadata":{}}]},{"cell_type":"code","source":"# among data taken 10 % for testing \nsplit_dataset = processed_dataset.train_test_split(test_size = round(small_dataset.shape[0]*.1), seed = 0)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:54.115687Z","iopub.execute_input":"2024-08-23T09:59:54.115997Z","iopub.status.idle":"2024-08-23T09:59:54.129992Z","shell.execute_reply.started":"2024-08-23T09:59:54.115965Z","shell.execute_reply":"2024-08-23T09:59:54.129200Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(split_dataset)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:54.131203Z","iopub.execute_input":"2024-08-23T09:59:54.131530Z","iopub.status.idle":"2024-08-23T09:59:54.136136Z","shell.execute_reply.started":"2024-08-23T09:59:54.131498Z","shell.execute_reply":"2024-08-23T09:59:54.134953Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['index', 'text', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 2361\n    })\n    test: Dataset({\n        features: ['index', 'text', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 262\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(model = model,\n                                      tokenizer= tokenizer, \n                                      max_length=MAX_LENGTH,\n                                      pad_to_multiple_of=8,\n                                      padding=\"max_length\")","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:54.137332Z","iopub.execute_input":"2024-08-23T09:59:54.137633Z","iopub.status.idle":"2024-08-23T09:59:54.146234Z","shell.execute_reply.started":"2024-08-23T09:59:54.137596Z","shell.execute_reply":"2024-08-23T09:59:54.145455Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Load Model in LoRA (Low Rank Adaptation)","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig,get_peft_model, prepare_model_for_kbit_training\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:54.147331Z","iopub.execute_input":"2024-08-23T09:59:54.147620Z","iopub.status.idle":"2024-08-23T09:59:54.214267Z","shell.execute_reply.started":"2024-08-23T09:59:54.147589Z","shell.execute_reply":"2024-08-23T09:59:54.213599Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"## LoRA Setting parameters\nLORA_R = 512 #512\nLORA_ALPHA = 512 #1024\nLORA_DROPOUT = 0.05 ","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:54.215297Z","iopub.execute_input":"2024-08-23T09:59:54.215650Z","iopub.status.idle":"2024-08-23T09:59:54.220235Z","shell.execute_reply.started":"2024-08-23T09:59:54.215606Z","shell.execute_reply":"2024-08-23T09:59:54.219068Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# LORA CONFIGRIGATION\nlora_config = LoraConfig(r = LORA_R, # the diamension of the low-rank metrics\n                        lora_alpha=LORA_ALPHA, # scaling factor for the weight matrices\n                        lora_dropout= LORA_DROPOUT, # dropout probability of the lora layers\n                        bias= \"none\",\n                        task_type=\"CAUSAL_LM\",\n                        target_modules=[\"query_key_value\"],\n                        )","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:54.221538Z","iopub.execute_input":"2024-08-23T09:59:54.221821Z","iopub.status.idle":"2024-08-23T09:59:54.231066Z","shell.execute_reply.started":"2024-08-23T09:59:54.221791Z","shell.execute_reply":"2024-08-23T09:59:54.230301Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# prepare int-8 model for training- utility function that prepare a pytorch model for int8 question\nmodel = prepare_model_for_kbit_training(model,)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:54.232221Z","iopub.execute_input":"2024-08-23T09:59:54.232599Z","iopub.status.idle":"2024-08-23T09:59:54.289110Z","shell.execute_reply.started":"2024-08-23T09:59:54.232558Z","shell.execute_reply":"2024-08-23T09:59:54.288427Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# initialize the model with the lora framework\nmodel = get_peft_model(model, lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:54.290151Z","iopub.execute_input":"2024-08-23T09:59:54.290536Z","iopub.status.idle":"2024-08-23T09:59:56.045871Z","shell.execute_reply.started":"2024-08-23T09:59:54.290492Z","shell.execute_reply":"2024-08-23T09:59:56.045032Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model.print_trainable_parameters()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:56.047583Z","iopub.execute_input":"2024-08-23T09:59:56.047972Z","iopub.status.idle":"2024-08-23T09:59:56.056308Z","shell.execute_reply.started":"2024-08-23T09:59:56.047928Z","shell.execute_reply":"2024-08-23T09:59:56.055211Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"trainable params: 167,772,160 || all params: 2,942,858,240 || trainable%: 5.7010\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Finetuning","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:56.058014Z","iopub.execute_input":"2024-08-23T09:59:56.058413Z","iopub.status.idle":"2024-08-23T09:59:57.241230Z","shell.execute_reply.started":"2024-08-23T09:59:56.058360Z","shell.execute_reply":"2024-08-23T09:59:57.240476Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 3\nLR = 1e-4\nMODEL_SAVE_FOLDER_PATH = \"dolly-3b-lora\"","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:57.242381Z","iopub.execute_input":"2024-08-23T09:59:57.242696Z","iopub.status.idle":"2024-08-23T09:59:57.247054Z","shell.execute_reply.started":"2024-08-23T09:59:57.242663Z","shell.execute_reply":"2024-08-23T09:59:57.245981Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"training_arg = TrainingArguments(\n                output_dir=MODEL_SAVE_FOLDER_PATH,\n                overwrite_output_dir=True,\n                fp16=True, # convert to float precision 16 using bitsandbytes\n                per_device_train_batch_size=1,\n                per_device_eval_batch_size=1,\n                learning_rate=LR,\n                num_train_epochs=EPOCHS,\n                logging_strategy= \"epoch\",\n                eval_strategy=\"epoch\",\n                save_strategy=\"epoch\",\n                )","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:57.248307Z","iopub.execute_input":"2024-08-23T09:59:57.248613Z","iopub.status.idle":"2024-08-23T09:59:57.294924Z","shell.execute_reply.started":"2024-08-23T09:59:57.248582Z","shell.execute_reply":"2024-08-23T09:59:57.294196Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\nmodel=model,\ntokenizer=tokenizer,\n    args= training_arg,\n    train_dataset=split_dataset[\"train\"],\n    eval_dataset=split_dataset[\"test\"],\n    data_collator=data_collator,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:57.295892Z","iopub.execute_input":"2024-08-23T09:59:57.296174Z","iopub.status.idle":"2024-08-23T09:59:58.167917Z","shell.execute_reply.started":"2024-08-23T09:59:57.296144Z","shell.execute_reply":"2024-08-23T09:59:58.167104Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.config.use_cache = False # silence the warning, please re-enable for inference!\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:58.168992Z","iopub.execute_input":"2024-08-23T09:59:58.169317Z","iopub.status.idle":"2024-08-23T09:59:58.173525Z","shell.execute_reply.started":"2024-08-23T09:59:58.169281Z","shell.execute_reply":"2024-08-23T09:59:58.172672Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"trainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T09:59:58.175284Z","iopub.execute_input":"2024-08-23T09:59:58.175629Z","iopub.status.idle":"2024-08-23T11:33:08.442933Z","shell.execute_reply.started":"2024-08-23T09:59:58.175588Z","shell.execute_reply":"2024-08-23T11:33:08.441800Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240823_103457-6ohnvta9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/lalit_team/huggingface/runs/6ohnvta9' target=\"_blank\">dolly-3b-lora</a></strong> to <a href='https://wandb.ai/lalit_team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/lalit_team/huggingface' target=\"_blank\">https://wandb.ai/lalit_team/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/lalit_team/huggingface/runs/6ohnvta9' target=\"_blank\">https://wandb.ai/lalit_team/huggingface/runs/6ohnvta9</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7083' max='7083' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7083/7083 57:52, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.510100</td>\n      <td>0.436621</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.370600</td>\n      <td>0.433637</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.248800</td>\n      <td>0.472399</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=7083, training_loss=0.37651456461002575, metrics={'train_runtime': 5589.1354, 'train_samples_per_second': 1.267, 'train_steps_per_second': 1.267, 'total_flos': 6.123283605356544e+16, 'train_loss': 0.37651456461002575, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Save finetuned model\ntrainer.save_model(MODEL_SAVE_FOLDER_PATH)\ntrainer.model.config.save_pretrained(MODEL_SAVE_FOLDER_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:33:08.444898Z","iopub.execute_input":"2024-08-23T11:33:08.445447Z","iopub.status.idle":"2024-08-23T11:33:09.938890Z","shell.execute_reply.started":"2024-08-23T11:33:08.445367Z","shell.execute_reply":"2024-08-23T11:33:09.937715Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Prediction on Real Data","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:33:09.940095Z","iopub.execute_input":"2024-08-23T11:33:09.940424Z","iopub.status.idle":"2024-08-23T11:33:09.945658Z","shell.execute_reply.started":"2024-08-23T11:33:09.940383Z","shell.execute_reply":"2024-08-23T11:33:09.944571Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def postprocess(response):\n    messages = response.split(\"Response:\")\n    if not messages:\n        raise ValueError(\"Invalid template for prompt. The template should include the term **Response**\")\n    return \"\".join(messages[1:])","metadata":{"execution":{"iopub.status.busy":"2024-08-23T11:33:09.947121Z","iopub.execute_input":"2024-08-23T11:33:09.947456Z","iopub.status.idle":"2024-08-23T11:33:09.957055Z","shell.execute_reply.started":"2024-08-23T11:33:09.947409Z","shell.execute_reply":"2024-08-23T11:33:09.956274Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"df.instruction.iloc[-10]","metadata":{"execution":{"iopub.status.busy":"2024-08-23T12:10:36.674576Z","iopub.execute_input":"2024-08-23T12:10:36.675308Z","iopub.status.idle":"2024-08-23T12:10:36.682422Z","shell.execute_reply.started":"2024-08-23T12:10:36.675270Z","shell.execute_reply":"2024-08-23T12:10:36.681125Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"'Here is a numerical problem for a math student in Algebraic Geometry- Cohomology of Algebraic Varieties:\\n\\nLet X be the algebraic variety defined by the equation x^2 + y^2 - 1 = 0 in the complex plane. Calculate the dimension of the cohomology group H^1(X, ℂ) where ℂ is the field of complex numbers.'"},"metadata":{}}]},{"cell_type":"code","source":"instruction = 'Here is a numerical problem for a math student in Algebraic Geometry- Cohomology of Algebraic Varieties:\\n\\nLet X be the algebraic variety defined by the equation x^2 + y^2 - 1 = 0 in the complex plane. Calculate the dimension of the cohomology group H^1(X, ℂ) where ℂ is the field of complex numbers.'\n\n\ninf_pipeline = pipeline(task = \"text-generation\",model = trainer.model,\n                        tokenizer = tokenizer, max_length = MAX_LENGTH)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T12:10:45.212474Z","iopub.execute_input":"2024-08-23T12:10:45.212857Z","iopub.status.idle":"2024-08-23T12:10:45.225511Z","shell.execute_reply.started":"2024-08-23T12:10:45.212819Z","shell.execute_reply":"2024-08-23T12:10:45.222605Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n","output_type":"stream"}]},{"cell_type":"code","source":"response = inf_pipeline(prompt.format(instruction = instruction))[0]['generated_text']","metadata":{"execution":{"iopub.status.busy":"2024-08-23T12:13:00.734621Z","iopub.execute_input":"2024-08-23T12:13:00.735380Z","iopub.status.idle":"2024-08-23T12:13:22.898716Z","shell.execute_reply.started":"2024-08-23T12:13:00.735337Z","shell.execute_reply":"2024-08-23T12:13:22.897481Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"print(response.split(\"Answer :\")[-1])","metadata":{"execution":{"iopub.status.busy":"2024-08-23T12:15:18.173104Z","iopub.execute_input":"2024-08-23T12:15:18.173528Z","iopub.status.idle":"2024-08-23T12:15:18.180922Z","shell.execute_reply.started":"2024-08-23T12:15:18.173487Z","shell.execute_reply":"2024-08-23T12:15:18.179958Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":" To calculate the dimension of the cohomology group H^1(X, ℂ), we will use the Leray spectral sequence. Let's first recall the Leray spectral sequence.\n\nThe Leray spectral sequence is a sequence of cohomology groups that arises from the fibration of the variety X over the base field K. The first term in the sequence is H^0(X_b, ℂ), where X_b is the base field and ℂ is the field of complex numbers. The second term is H^1(X_b, ℂ), and the third term is H^2(X_b, ℂ).\n\nNow, let's consider the fibration X → B → K, where B is the base field and K is the field of complex numbers. The Leray spectral sequence will have the following terms:\n\n1. H^0(X_b, ℂ) → H^1(X_b, ℂ) → H^2(X_b, ℂ)\n2. H^1(X_b, ℂ) → H^2(X_b, ℂ) → H^3(B, ℂ)\n3. H^2(X_b, ℂ) → H^3(B, ℂ) → H^4(B, ℂ)\n\nSince we are working over the field of complex numbers, we can use the fact that the Leray spectral sequence is a fibration with base field K. Therefore, the third term is 0, and the second term is the cohomology group we are interested in.\n\nNow, we need to find the dimension of H^1(X, ℂ). Since X is an algebraic variety, we can use the Riemann-Roch theorem to compute the dimension of H^1(X, ℂ). The Riemann\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}